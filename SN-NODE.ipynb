{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b16dfc76-0c78-416c-9565-c0825087a06a",
   "metadata": {},
   "source": [
    "# SN-NODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "276cbbe5-dac1-4814-807c-e50cc633b11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import diffrax\n",
    "import equinox as eqx\n",
    "import jax\n",
    "import jax.nn as jnn\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import jax.random as jrandom\n",
    "import optax\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "import os\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "243412cd-9f19-489f-a10e-bf0eb8bf3788",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Func(eqx.Module):\n",
    "    mlp: eqx.nn.MLP\n",
    "    linear_weight: jnp.ndarray  # Trainable parameter 'a'\n",
    "\n",
    "    def __init__(self, data_size, width_size, depth, *, key, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.mlp = eqx.nn.MLP(\n",
    "            in_size=data_size,\n",
    "            out_size=data_size,\n",
    "            width_size=width_size,\n",
    "            depth=depth,\n",
    "            activation=jnn.sigmoid,\n",
    "            key=key,\n",
    "        )\n",
    "        \n",
    "        self.linear_weight = jrandom.normal(key, (data_size,))* 1e-1\n",
    "\n",
    "    def __call__(self, t, y, args):\n",
    "        \n",
    "        # Linear term: a * X\n",
    "        linear_term = self.linear_weight * y\n",
    "        \n",
    "        # Nonlinear term: MLP(X)\n",
    "        nonlinear_term = self.mlp(y)\n",
    "\n",
    "        # Return the sum: a * X + MLP(X)\n",
    "        return linear_term + nonlinear_term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdb14ae0-1aa5-4e10-ba3b-d977d5d6ac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralODE(eqx.Module):\n",
    "    func: Func\n",
    "\n",
    "    def __init__(self, data_size, width_size, depth, *, key, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.func = Func(data_size, width_size, depth, key=key)\n",
    "\n",
    "    def __call__(self, ts, y0):\n",
    "        solution = diffrax.diffeqsolve(\n",
    "            diffrax.ODETerm(self.func),\n",
    "            diffrax.Tsit5(),\n",
    "            t0=ts[0],\n",
    "            t1=ts[-1],\n",
    "            dt0=ts[1] - ts[0],\n",
    "            y0= y0,\n",
    "            stepsize_controller=diffrax.PIDController(rtol=1e-3, atol=1e-6),\n",
    "            saveat=diffrax.SaveAt(ts=ts),\n",
    "            \n",
    "        )\n",
    "        return solution.ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf36758b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(arrays, batch_size, *, key):\n",
    "    dataset_size = arrays[0].shape[0]\n",
    "    assert all(array.shape[0] == dataset_size for array in arrays)\n",
    "    indices = jnp.arange(dataset_size)\n",
    "    while True:\n",
    "        perm = jr.permutation(key, indices)\n",
    "        (key,) = jr.split(key, 1)\n",
    "        start = 0\n",
    "        end = batch_size\n",
    "        while end <= dataset_size:\n",
    "            batch_perm = perm[start:end]\n",
    "            yield tuple(array[batch_perm] for array in arrays)\n",
    "            start = end\n",
    "            end = start + batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90251dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataload(number):\n",
    "    file_path = r'xxx' # replace this with your file path\n",
    "    column_data = [] \n",
    "    \n",
    "    total_rows_to_collect = 24*number  # Total data size\n",
    "   \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader) \n",
    "        for _, row in zip(range(total_rows_to_collect), reader):\n",
    "            column1_data.append(row[0])  \n",
    "            \n",
    "    column_array = np.array(column_data)\n",
    "    \n",
    "    return column_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a94c4aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_minmax(data, number):\n",
    "    \n",
    "    reshaped_data = data.reshape(number, 24)\n",
    "    extended_data = np.zeros((number, 25))\n",
    "\n",
    "    for i in range(number - 1):\n",
    "        extended_data[i, :-1] = reshaped_data[i, :]\n",
    "        extended_data[i, -1] = reshaped_data[i + 1, 0] \n",
    "\n",
    "    extended_data[-1, :-1] = reshaped_data[-1, :]\n",
    "    extended_data[-1, -1] = reshaped_data[-1, -1]\n",
    "\n",
    "    interpolated_data = np.zeros((number, 1000))\n",
    "\n",
    "    x_original = np.linspace(0, 24, 25)\n",
    "    \n",
    "    x_new = np.linspace(0, 24, 1000)\n",
    "\n",
    "    for i in range(number):\n",
    "\n",
    "        f = interp1d(x_original, extended_data[i], kind='cubic')\n",
    "\n",
    "        interpolated_data[i] = f(x_new)\n",
    "        \n",
    "    data_min = np.zeros(number)\n",
    "    data_max = np.zeros(number)\n",
    "    normalized_data = np.zeros((number, 1000))\n",
    "\n",
    "    for i in range(number):\n",
    "        data_min[i] = interpolated_data[i, :].min()\n",
    "        data_max[i] = interpolated_data[i, :].max()\n",
    "        normalized_data[i, :] = (interpolated_data[i, :] - data_min[i]) / (data_max[i] - data_min[i])\n",
    " \n",
    "    return  normalized_data,data_min,data_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22e43f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combination(data, number):\n",
    "    \n",
    "    ts = jnp.linspace(0, 24, 1000)\n",
    "        \n",
    "    ys_1 = data.reshape(number, 1000, 1)\n",
    "\n",
    "    t_replicated = np.tile(ts, (number, 1)).reshape(number, 1000, 1)\n",
    "    \n",
    "    ys = np.concatenate([t_replicated, ys_1], axis=2)\n",
    "    \n",
    "    return ts,ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "135540f6-d5ea-4c79-b083-0b86fd3edbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(\n",
    "    dataset_size=100,\n",
    "    datasize_tr = 75,\n",
    "    steps_strategy=(2000,9900),\n",
    "    randomseed = 1,\n",
    "    batch_size=10,\n",
    "    lr_strategy=(3e-3,3e-3),\n",
    "    length_strategy=(0.1,1),\n",
    "    width_size=100,\n",
    "    depth=5,\n",
    "    seed=5678,\n",
    "    plot=True,\n",
    "    print_every=500,\n",
    "):\n",
    "    key = jr.PRNGKey(seed)\n",
    "    data_key, model_key, loader_key = jr.split(key, 3)\n",
    "    \n",
    "    energy = dataload(dataset_size)\n",
    "    [data,data_min,data_max] = reshape_minmax(energy, dataset_size)\n",
    "    [ts,ys] = combination(data, dataset_size)\n",
    "    \n",
    "    random.seed(randomseed)  \n",
    "    selected_indices = random.sample(range(dataset_size), datasize_tr)\n",
    "    selected_array = ys[selected_indices, :, :]\n",
    "    ys = selected_array\n",
    "    \n",
    "    data_max = [data_max[item - 1] for item in selected_indices]\n",
    "    data_min = [data_min[item - 1] for item in selected_indices]\n",
    "                \n",
    "    _, length_size, data_size = ys.shape\n",
    "    \n",
    "    model = NeuralODE(data_size, width_size, depth, key=model_key)\n",
    "\n",
    "    @eqx.filter_value_and_grad\n",
    "    def grad_loss(model, ti, yi):\n",
    "        y_pred = jax.vmap(model, in_axes=(None, 0))(ti, yi[:, 0])\n",
    "        return jnp.mean((yi - y_pred) ** 2)\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def make_step(ti, yi, model, opt_state):\n",
    "        loss, grads = grad_loss(model, ti, yi)\n",
    "        updates, opt_state = optim.update(grads, opt_state)\n",
    "        model = eqx.apply_updates(model, updates)\n",
    "        return loss, model, opt_state\n",
    "\n",
    "    for lr, steps, length in zip(lr_strategy, steps_strategy, length_strategy):\n",
    "        optim = optax.adabelief(lr)\n",
    "        opt_state = optim.init(eqx.filter(model, eqx.is_inexact_array))\n",
    "        _ts = ts[: int(length_size * length)]\n",
    "        _ys = ys[:, : int(length_size * length)]\n",
    "        for step, (yi,) in zip(\n",
    "            range(steps), dataloader((_ys,), batch_size, key=loader_key)\n",
    "        ):\n",
    "            start = time.time()\n",
    "            loss, model, opt_state = make_step(_ts, yi, model, opt_state)\n",
    "            end = time.time()\n",
    "\n",
    "    return ts, ys, model, data_min, data_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c7c8cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE_TR(ts, data, model, data_max, data_min):\n",
    "    \n",
    "    data_m = []\n",
    "    data_o = []\n",
    "    \n",
    "    mae = []\n",
    "    rmses = []\n",
    "    cvrmse = []\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        \n",
    "        model_y = model(ts, data[i, 0])\n",
    "        \n",
    "        original_data_o_i = data[i,:,1] * (data_max[i] - data_min[i]) + data_min[i]\n",
    "        original_data_s_i = model_y * (data_max[i] - data_min[i]) + data_min[i]\n",
    "\n",
    "        \n",
    "        index = (np.linspace(0,999,25)).astype(int)\n",
    "        \n",
    "        data_m.append(original_data_s_i[index[0:23], 1])\n",
    "        data_o.append(original_data_o_i[index[0:23]])\n",
    "    \n",
    "    data_m = np.concatenate(data_m)\n",
    "    data_o = np.concatenate(data_o)\n",
    "\n",
    "    \n",
    "    for j in range(len(data_o) - 24):\n",
    "    \n",
    "        mae_value = np.mean(np.absolute(data_o[j:j+24] - data_m[j:j+24]))\n",
    "        mae.append(mae_value)\n",
    "\n",
    "        rmse_value = np.sqrt(np.mean((data_o[j:j+24] - data_m[j:j+24])**2))\n",
    "        rmses.append(rmse_value)\n",
    "\n",
    "        cvrmse_value = rmse_value / (np.mean(data_o[j:j+24]))\n",
    "        cvrmse.append(cvrmse_value)\n",
    "\n",
    "    return mae, np.mean(mae),rmses, np.mean(rmses), cvrmse, np.mean(cvrmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18d28fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE_TE(ts, data, model, data_max_p, data_min_p, data_max,data_min):\n",
    "    \n",
    "\n",
    "    \n",
    "    mae = []\n",
    "    rmses = []\n",
    "    cvrmse = []\n",
    "    \n",
    "    for i in range(0,data.shape[0] - 1):\n",
    "        \n",
    "        model_y = model(ts, data[i, 0])\n",
    "        startpoint = model_y[999]\n",
    "        startpoint = startpoint.at[0].set(0)\n",
    "        model_y_next = model(ts, startpoint)\n",
    "\n",
    "        \n",
    "        original_data_o_i = data[i,:,1] * (data_max[i] - data_min[i]) + data_min[i]\n",
    "        original_data_o_i_next = data[i+1,:,1] * (data_max[i+1] - data_min[i+1]) + data_min[i+1]\n",
    "        original_data_s_i = model_y * (data_max_p[i] - data_min_p[i]) + data_min_p[i]\n",
    "        original_data_s_i_next = model_y_next * (data_max_p[i+1] - data_min_p[i+1]) + data_min_p[i+1]\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        index = (np.linspace(0,999,25)).astype(int)\n",
    "        original_data_o_i = original_data_o_i[index]\n",
    "        original_data_o_i_next = original_data_o_i_next[index]\n",
    "        original_data_s_i = original_data_s_i[index]\n",
    "        original_data_s_i_next = original_data_s_i_next[index]\n",
    "        \n",
    "        \n",
    "\n",
    "        for j in range(24):\n",
    "            \n",
    "            data_o = np.concatenate([original_data_o_i[j:24],original_data_o_i_next[0:j]])\n",
    "            data_s = np.concatenate([original_data_s_i[j:24,1],original_data_s_i_next[0:j,1]])\n",
    "       \n",
    "            mae_value = np.mean(np.absolute(data_o - data_s))\n",
    "            mae.append(mae_value)\n",
    "\n",
    "            rmse_value = np.sqrt(np.mean((data_o - data_s)**2))\n",
    "            rmses.append(rmse_value)\n",
    "\n",
    "            cvrmse_value = rmse_value / (np.mean(data_o))\n",
    "            cvrmse.append(cvrmse_value)\n",
    "\n",
    "    return mae, np.mean(mae),rmses, np.mean(rmses), cvrmse, np.mean(cvrmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e5035d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecasting(number):\n",
    "\n",
    "    energy = dataload(number)\n",
    "\n",
    "    [data,data_min,data_max] = reshape_minmax(energy, number)\n",
    "\n",
    "    [ts,ys] = combination(data, number)\n",
    "    \n",
    "    return ts,ys,data_max, data_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c0a2a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxmin_r(number_of_day, data_max_f, data_min_f, selected_indices, remain_indices):\n",
    "    data_max_pre = np.zeros(number_of_day)\n",
    "    data_min_pre = np.zeros(number_of_day)\n",
    "    \n",
    "    \n",
    "    data_max_pre[selected_indices] = data_max_f[selected_indices]\n",
    "    data_min_pre[selected_indices] = data_min_f[selected_indices]\n",
    "\n",
    "    \n",
    "    for idx in remain_indices:\n",
    "        \n",
    "        if idx < 1:\n",
    "            data_max_pre[idx] = data_max_f[idx]  \n",
    "            data_min_pre[idx] = data_min_f[idx]\n",
    "        else:\n",
    "            data_max_pre[idx] = data_max_f[idx - 1]\n",
    "            data_min_pre[idx] = data_min_f[idx - 1]\n",
    "            \n",
    "\n",
    "    return data_max_pre, data_min_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "10321330",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_day = int(150)\n",
    "[ts_f,ys_f,data_max_f,data_min_f] = forecasting(number_of_day)\n",
    "RS = [1.1,1.2,1.3,1.4,1.6]\n",
    "size = [75,65,55,45,35,25,15,5]\n",
    "bs = [2,10,10,10,10,10,10,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4265536a-0b00-427a-88df-7b9ce9a28022",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE_tr = []\n",
    "MAE_te = []\n",
    "RMSE_tr = []\n",
    "RMSE_te = []\n",
    "CV_tr = []\n",
    "CV_te = []\n",
    "\n",
    "for i in range(8):\n",
    "\n",
    "    for j in range(5):\n",
    "        \n",
    "        [ts, ys, model, data_min, data_max] = main(number_of_day,size[i],(2000,5000),RS[j],batch_size = bs[i])\n",
    "        [mae, mae_mean,rmse,rmse_mean,cvrmse,cvrmse_mean] = RMSE_TR(ts, ys, model, data_max, data_min)\n",
    "        \n",
    "        MAE_tr.append(mae_mean)\n",
    "        RMSE_tr.append(rmse_mean)\n",
    "        CV_tr.append(cvrmse_mean)\n",
    "        \n",
    "        random.seed(RS[j])\n",
    "        selected_indices = random.sample(range(number_of_day), int(size[i]))\n",
    "        remaining_indices = [i for i in range(number_of_day) if i not in selected_indices]\n",
    "\n",
    "        [data_max_p,data_min_p] = maxmin_r(number_of_day,data_max_f,data_min_f, selected_indices,remaining_indices)\n",
    "\n",
    "        [mae, mae_mean,rmse,rmse_mean,cvrmse,cvrmse_mean] = RMSE_TE(ts_f, ys_f, model, data_max_p, data_min_p, data_max_f, data_min_f)\n",
    "\n",
    "        MAE_te.append(mae_mean)\n",
    "        RMSE_te.append(rmse_mean)\n",
    "        CV_te.append(cvrmse_mean)\n",
    "\n",
    "data_overal = [MAE_tr, MAE_te, RMSE_tr, RMSE_te, CV_tr, CV_te]\n",
    "column_names = [\"MAE_tr\", \"MAE_te\", \"RMSE_tr\", \"RMSE_te\", \"CV_tr\", \"CV_te\"]\n",
    "data_df = pd.DataFrame(data_overal, column_names)\n",
    "data_df.to_excel(\"xxx.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
